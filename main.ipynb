{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nn import SimpleFFNN\n",
    "from train import Train\n",
    "from preProcessing import PreProcessing\n",
    "import numpy as np\n",
    "from testModel import TestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função para dividir os dados de treino e de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_array(data: np.ndarray, train_size: float = 0.8):\n",
    "    \"\"\"\n",
    "    Divide um array 2D em dois arrays: um com train_size dos dados e outro com o restante.\n",
    "    \n",
    "    :param data: O array 2D a ser dividido.\n",
    "    :param train_size: A proporção de dados a serem usados para o primeiro array (default é 0.8).\n",
    "    :return: Dois arrays 2D, um com os dados de treinamento e outro com os dados de teste.\n",
    "    \"\"\"\n",
    "    # Calcula o índice para a divisão\n",
    "    split_index = int(len(data) * train_size)\n",
    "    \n",
    "    # Embaralha os dados\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    # Divide o array\n",
    "    train_data = data[:split_index]\n",
    "    test_data = data[split_index:]\n",
    "    \n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis onde está os ficheiros de treino e o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file onde já está o modelo treinado\"\n",
    "model=None\n",
    "newPKL = \"Pedro_3_20_30,20,10\"\n",
    "\n",
    "\n",
    "#limpesa de ficheiro de treino\n",
    "data=\"train\"\n",
    "#ficheiro onde vai ser feita ao autoavaliacao\n",
    "avaliation = \"test_no_label\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mPre Processing the data\n",
      "\u001b[0m\n",
      "\u001b[32mPre Processing Completed!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"\\033[34mPre Processing the data\\n\\033[0m\")\n",
    "pp=PreProcessing(data+\".txt\")\n",
    "clean_data=pp.returnCleanText()\n",
    "print(\"\\033[32mPre Processing Completed!\\n\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividir a train_data do test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_train, data_to_test = split_array(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o modelo ou Criar um novo\n",
    "#### Conforme o nome dado a variavel 'newPKL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading Model\n",
      "\u001b[0m\n",
      "\u001b[32mLoading Completed!\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Carregar o modelo se ele já existir\n",
    "if os.path.isfile(\"data/\"+newPKL+\".pkl\"):\n",
    "    print(\"\\033[34mLoading Model\\n\\033[0m\")\n",
    "    \n",
    "    model=SimpleFFNN.load_model(\"data/\"+newPKL+\".pkl\")\n",
    "    \n",
    "    print(\"\\033[32mLoading Completed!\\n\\033[0m\")\n",
    "# Se não existir, cria e treina um novo modelo   \n",
    "else:\n",
    "    print(\"\\033[34mCreating a new Model\\n\\033[0m\")\n",
    "    \n",
    "    layer_hidden = [30,20,10] # adicionar o numero de nos por camada,hidden, que bem se entender([5]->5 nos na camada hidden1; [3,6]-> 3 na camada hidden 1 e 6 na hidden 2;...)\n",
    "    learning_rate = 0.01\n",
    "    epochs=20\n",
    "    model = Train(data_to_train,newPKL,layer_hidden, learning_rate, epochs)\n",
    "    model.train()\n",
    "    \n",
    "    print(\"\\033[32mModel Created!\\n\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variavel para testar os modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teste= TestModel(newPKL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste do modelo com o ficheiro com as labels identificadas\n",
    "##### 'train.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_to_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Testar e comparar labels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_teste\u001b[38;5;241m.\u001b[39mtest_with_label(data_to_test)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_to_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Testar e comparar labels\n",
    "model_teste.test_with_label(data_to_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerar ficheiro com os resultados do modelo, com inouts do ficheiro sem  as labels\n",
    "##### 'test_no_labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar e apenas escrever resultados no ficheiro 'results.txt'\n",
    "pp_no_label = PreProcessing(avaliation+\".txt\")\n",
    "clean_data_no_label = pp_no_label.returnCleanText()\n",
    "model_teste.test_without_labels(clean_data_no_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mTrying to predict the genre\n",
      "\u001b[0m\n",
      "\u001b[32mFor the movie given by input the model said: ['romance']', and was: 'romance'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "texto=\"Romeo and Juliet is a play written by Shakespeare. It is a tragic love story where the two main characters, Romeo and Juliet, are supposed to be sworn enemies but fall in love. Due to their families' ongoing conflict, they cannot be together, so they kill themselves because they cannot cope with being separated from one another. Romeo and Juliet is a Shakespearean tragedy\"\n",
    "clean_texto=PreProcessing.returnCleanInputText(texto)\n",
    "genre=\"romance\"\n",
    "model_teste.test_from_input(clean_texto,genre)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
