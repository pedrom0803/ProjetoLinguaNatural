{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File para meter os dados da colecao onde a stora foi buscar os de treino quebra de linha ao escrever no \"ou_data.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Em principio não há duplicados com os do \"train.txt\" que a stora deu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sacar os dados do csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas: Index(['Release Year', 'Title', 'Origin/Ethnicity', 'Director', 'Cast',\n",
      "       'Genre', 'Wiki Page', 'Plot'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Vetor com os gêneros permitidos\n",
    "allowed_genres = [\"drama\", \"comedy\", \"horror\", \"action\", \"romance\", \"western\", \"animation\", \"crime\", \"sci-fi\"]\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv('/Users/pedromiguel/Downloads/wiki_movie_plots_deduped.csv')\n",
    "\n",
    "print(\"Colunas:\", df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtrar os dados em que os generos sao aqueles que o modelo sabe que existem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as colunas \"Title\", \"Genre\" e \"Plot\"\n",
    "selected_columns = df[['Title', 'Origin/Ethnicity','Genre','Director', 'Plot']]\n",
    "\n",
    "# Filtrar os valores da coluna \"Genre\" que estão no vetor 'allowed_genres'\n",
    "filtered_data = selected_columns[selected_columns['Genre'].isin(allowed_genres)]\n",
    "\n",
    "# Converter as colunas filtradas em uma lista de listas (vetor)\n",
    "data_list = filtered_data.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ler os plots que a stora deu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_filmes = []\n",
    "with open(\"./data/train.txt\", 'r', encoding='utf-8') as file:\n",
    "    # Lendo o arquivo linha por linha\n",
    "    for linha in file:\n",
    "        # Remover espaços em branco no início e fim (incluindo quebras de linha)\n",
    "        linha = linha.strip()\n",
    "        # Separar os dados usando o tab ('\\t') como delimitador\n",
    "        filme = linha.split('\\t')\n",
    "        # Adicionar a lista de filmes ao array 2D\n",
    "        dados_filmes.append(filme)\n",
    "        \n",
    "# print(len(dados_filmes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar dados que nao existem no ficheiro que a stora  deu para treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar um novo array para armazenar dados não duplicados\n",
    "novo_array = []\n",
    "\n",
    "# Adicionar os dados do CSV ao novo_array se não existirem em dados_filmes\n",
    "for row in data_list:\n",
    "    title, origem, genre, diretor,plot = row[0], row[1], row[2], row[3], row[4]\n",
    "    \n",
    "    # Verificar se o título, gênero e plot já estão no array 'dados_filmes'\n",
    "    if not any(filme[0] == title and filme[2] == genre and filme[1] == origem and filme[3]== diretor for filme in dados_filmes):\n",
    "        novo_array.append([title, genre, plot])  # Adicionar ao novo array se não for duplicado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alterar a info dos plot, pq há uns que teem \\n, e depois ele assume que é mesmo uma quebra de linha ao escrever no ficheiro de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(novo_array[7358])\n",
    "\n",
    "clean_array = []\n",
    "for filme in novo_array:\n",
    "    # Remover os caracteres \"\\r\", \"\\n\", \"\\t\" de cada string\n",
    "    plot = filme[2].replace(\"\\r\", \"\").replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n",
    "    \n",
    "    # Remover qualquer formato que contenha um dígito dentro de []\n",
    "    plot = re.sub(r'\\[\\d+\\]', '', plot)\n",
    "    \n",
    "    # Substituir \"\\'s\" por \"´s\"\n",
    "    plot = plot.replace(\"'s\", \"´s\")\n",
    "    \n",
    "    # Substituir \".[\\d]\" por \".\"\n",
    "    plot = re.sub(r'\\.\\[\\d+\\]', '.', plot)\n",
    "    \n",
    "    # Substituir todas as ocorrências de \\' por '\n",
    "    plot = re.sub(r\"\\\\'\", \"'\", plot)\n",
    "    \n",
    "    # Adicionar o filme limpo ao novo array\n",
    "    clean_array.append([filme[0], filme[1], plot])\n",
    "\n",
    "# print(clean_array[7358])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escrever no ficheiro \"our_data.txt\" os novos dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho do arquivo de saída\n",
    "output_file = './data/our_data.txt'\n",
    "\n",
    "# Abrir o arquivo para escrita\n",
    "with open(output_file, 'w', encoding='utf-8') as file:\n",
    "    for row in clean_array:\n",
    "        # Escrever cada linha no arquivo, separando as colunas por '\\t'\n",
    "        file.write('\\t'.join(row) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
